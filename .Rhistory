points(training$age,predict(lm1,newdata=training),col="red",cex=0.5)
plot(training$age,training$wage,pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",cex=0.5)
version(caret)
R.version(caret)
library(caret)
install.packages("AppliedPredictiveModeling")
library("AppliedPredictiveModeling", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
data(AlzheimerDisease)
data(concrete)
set.seed(1000)
inTrain <- createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training <- mixtures[ inTrain,]
testing <- mixtures[-inTrain,]
hist(training$Superplasticizer)
summary(training$Superplasticizer)
table(training$Superplasticizer)
hist(log(training$SuperPlasticizer + 1))
hist(log(training$SuperPlasticizer + 1),break=10)
hist(log(training$SuperPlasticizer + 1),breaks=10)
library(MASS)
truehist(log(training$SuperPlasticizer + 1))
boxplot(log(training$SuperPlasticizer + 1))
truehist(log(training$SuperPlasticizer + 1)*100000)
set.seed(3433)
data(AlzheimerDisease)
adData <- data.frame(diagnosis,predictors)
inTrain <- createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training <- adData[ inTrain,]
testing <- adData[-inTrain,]
str(predictors)
preProcess(training[c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8"),],method="pca",thresh = 0.9)
preProcess(training[,c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8")],method="pca",thresh = 0.9)
modelFit<- train(training$diagnosis~training[,c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8")],method="glm",data=training)
)
modelFit<- train(training$diagnosis~training[,c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8")],method="glm",data=training)
modelFit<- train(training$diagnosis~c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8")],method="glm",data=training)
modelFit<- train(training$diagnosis~c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8"),method="glm",data=training)
modelFit<- train(diagnosis~c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8"),method="glm",preProcess="pca",data=training)
modelFit<- train(training$diagnosis ~ c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8"),method="glm",data=training)
str(training)
modelFit<- train(training$diagnosis ~ IL_11+IL_13+IL_16+IL_17E+IL_1alpha+IL_3+IL_4+IL_5+IL_6+IL_6_Receptor+IL_7+IL_8,method="glm",data=training)
confusionMatrix(testing$diagnosis,predict(modelFit,testing))
modelFit<- train(training$diagnosis ~ IL_11+IL_13+IL_16+IL_17E+IL_1alpha+IL_3+IL_4+IL_5+IL_6+IL_6_Receptor+IL_7+IL_8,method="glm",preProcess="pca",data=training)
confusionMatrix(testing$diagnosis,predict(modelFit,testing))
library(caret)
library(kernlab)
library(MASS)
?bs()
?smooth.spline
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
install.packages("ElemStatLearn")
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
?order
?order
order(ozone$ozeon)
order(ozone$ozone)
testing <- c(2,3,4,5)
order(testing)
testing <- c(21,3,45,5)
order(testing)
testing[order(testing),]
testing[order(testing)]
sample(testing, replace=T)
dim(ozone)
ll <- matrix(NA, nrow=10,ncol=155)
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0<-ozone0[order(ozone$ozone),]
loess0 <- loess(temperature~ozone,data=ozone0,span=0.2)
ll[1,] <- predict(loess0,newdata=data.frame(ozone=1:155))
ll
dim(ozone)
str(ozone)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0<-ozone0[order(ozone$ozone),]
loess0 <- loess(temperature~ozone,data=ozone0,span=0.2)
ll[1,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
ll <- matrix(NA, nrow=10,ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0<-ozone0[order(ozone$ozone),]
loess0 <- loess(temperature~ozone,data=ozone0,span=0.2)
ll[1,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
View(ll)
ll <- matrix(NA, nrow=10,ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0<-ozone0[order(ozone$ozone),]
loess0 <- loess(temperature~ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
?apply
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
?line
predictors <- data.frame(ozone=ozone$ozone)
temperature <- ozone$temperature
treebag <- bag(predictors,temperature,B=10,
bagControl = bagControl(fit=ctreeBag$fit,
predict=ctreeBag$pred,
aggregate=ctreeBag$aggregate))
library(caret)
predictors <- data.frame(ozone=ozone$ozone)
temperature <- ozone$temperature
treebag <- bag(predictors,temperature,B=10,
bagControl = bagControl(fit=ctreeBag$fit,
predict=ctreeBag$pred,
aggregate=ctreeBag$aggregate))
install.packages("ctreebag")
install.packages("ctreeBag")
?bag
predictors <- data.frame(ozone=ozone$ozone)
temperature <- ozone$temperature
treebag <- bag(predictors,temperature,B=10,
bagControl = bagControl(fit=ctreeBag$fit,
predict=ctreeBag$pred,
aggregate=ctreeBag$aggregate))
install.packages("party")
treebag <- bag(predictors,temperature,B=10,
bagControl = bagControl(fit=ctreeBag$fit,
predict=ctreeBag$pred,
aggregate=ctreeBag$aggregate))
?ctreeBag
data(iris);library(ggplot2)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
modFit <- train(Species~.,data=training,method="rf",prox=TRUE)
modFit
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species~.,data=training,method="rf",prox=TRUE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species~.,data=training,method="rf",prox=TRUE)
modFit
getTree(modFit$finalModel,k=2)
head(train[,c(3,4)])
train[,c(3,4)]
head(training[,c(3,4)])
classCenter
order
?classCenter
?rownames
rownames(irisP)
lines(1:155,apply(ll,2,mean),col="red",lwd=2) #2 indicates column in the apply function
rownames(irisP)
irisP <- classCenter(training[,c(3,4)],training$Species, modFit$finalModel$prox)
rownames(irisP)
irisP
irisP <- as.data.frame(irisP); iris$Species <- rownames(irisP)
p <- qplot(Petal.Width,Petal.Length,col=Species,data=training)
irisP <- as.data.frame(irisP); iris$Species <- rownames(irisP)
p <- qplot(Petal.Width,Petal.Length,col=Species,data=training)
p+geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
irisP <- as.data.frame(irisP); iris$Species <- rownames(irisP)
p <- qplot(Petal.Width,Petal.Length,col=Species,data=training)
p+geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
irisP <- classCenter(training[,c(3,4)],training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP); iris$Species <- rownames(irisP)
p <- qplot(Petal.Width,Petal.Length,col=Species,data=training)
p+geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
irisP <- classCenter(training[,c(3,4)],training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width,Petal.Length,col=Species,data=training)
p+geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
irisP$Species
irisP
pred <- predict(modFit,testing);testing$preRight <- pred ==testing$Species
table(pred,testing$Species)
?table
pred
qplot(Petal.Width,Petal.Length,col=predRight,data=testing,main="new data prediction")
qplot(Petal.Width,Petal.Length,col=preRight,data=testing,main="new data prediction")
Wage <- subset(Wage,select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training <- Wage[inTrain,];testing <- Wage[-inTrain,]
modFit <- train(wage~.,method="gbm",data=training,verbose=FALSE)
modFit <- train(wage~.,method="gbm",data=training,verbose=FALSE)
print(modFit)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
?rpart
set.seed(125)
modFit <- train(Case~.,method="rpart",data=training)
head(segmentationOriginal)
training <- segmentationOriginal[inTrain$Case=="Train",]
training <- segmentationOriginal[segmentationOriginal$Case=="Train",]
training <- segmentationOriginal[segmentationOriginal$Case=="Test",]
?segmentationOriginal
set.seed(125)
modFit <- train(Class~.,method="rpart",data=training)
modFit
modFit$finalModel
predict(modFit,as.data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2))
predict(modFit,data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2))
data.frame(TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2)
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(mofFit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(rattle)
?fancyRpartPlot
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
predict(modFit, rbind(c(23000,10),c(50000,10),c(57000,8)))
input<-rbind(c(23000,10),c(50000,10),c(57000,8))
input
colnames <- c("TotalIntench2","FiberWidthCh1")
input
names(input) <- colnames
input
colnames(input)<-colnames
input
input<-rbind(c(23000,10),c(50000,10),c(57000,8))
input
colnames(input)<-colnames
input
predict(modFit,input)
class(input)
predict(modFit,as.data.frame(input))
input <- as.data.frame(input)
input
predict(modFit,input)
prediction <- predict(modFit,testing)
rm("prediction")
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
head(olive)
modFit3 <- train(Area~.,method="rpart",data=olive)
modFit3
table(olive$Area)
predict(modFit3,newdata=as.data.fram(t(colMeans(olive))))
predict(modFit3,newdata=as.data.frame(t(colMeans(olive))))
fancyRpartPlot(modFit3$finalModel)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
head(SAheart)
modFit4 <- train(chd ~age+alcohol+obesity+tabacco+typea+ldl, method="glm",family="binomial")
modFit4 <- train(chd ~age+alcohol+obesity+tabacco+typea+ldl, method="glm",family="binomial",data=olive)
modFit4 <- train(chd~age+alcohol+obesity+tabacco+typea+ldl, method="glm",family="binomial",data=olive)
modFit4 <- train(chd~age+alcohol+obesity+tabacco+typea+ldl, method="glm",family="binomial",data=olive)
set.seed(13234)
modFit4 <- train(chd~age+alcohol+obesity+tabacco+typea+ldl, method="glm",family="binomial",data=SAheart)
modFit4 <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, method="glm",family="binomial",data=SAheart)
prediction <- predict(modFit4,newdata=testSA)
missClass < function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
head(prediction)
missClass(testSA$sbp,prediction)
missClass < function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$sbp,prediction)
modFit4$finalModel
modFit4
prediction <- predict(modFit4,testSA)
missClass(testSA$sbp,prediction)
missClass(testSA$chd,prediction)
prediction <- predict(modFit4,newdata=testSA)
missClass(testSA$chd,prediction)
prediction <- predict(modFit4)
missClass(testSA$chd,prediction)
missClass(trainSA$chd,prediction)
prediction <- predict(modFit4,trainSA)
missClass(trainSA$chd,prediction)
testPred <- predict(modFit4,newdata=testSA)
missClass(trainSA$chd,testPred)
missClass(testSA$chd,testPred)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
modFit4 <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, method="glm",family="binomial",data=trainSA)
trainPred <- predict(modFit4,trainSA)
testPred <- predict(modFit4,newdata=testSA)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,trainPred)
missClass(testSA$chd,testPred)
data(vowel.train)
data(vowel.test)
head(vowel.test)
vowel.train$y <-as.factor(vowel.train$y)
vowel.test$y <-as.factor(vowel.test$y)
modFit <- train(y~.,data=vowel.train,method="rf")
modFit
?varImp
varImp(modFit)
set.seed(33833)
modFit <- train(y~.,data=vowel.train,method="rf")
varImp(modFit)
training <- segmentationOriginal[segmentationOriginal$Case=="Train",]
test <- segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
modFit <- train(Class~.,method="rpart",data=training)
fancyRpartPlot(modFit$finalModel)
setwd("~/Desktop/John Hopkin Data Sci/machine learning")
setwd("~/Desktop/John Hopkin Data Sci/machine learning/project")
?download.file()
download.file(https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv,"train.csv")
download.file(https:\\d396qusza40orc.cloudfront.net\predmachlearn\pml-training.csv,"train.csv")
download.file(https:\\d396qusza40orc.cloudfront.net\predmachlearn\pml-training.csv,"train.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","train.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",destfile="train.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",destfile="train.csv",method="curl")
list.file(getwd())
list.files(getwd())
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",destfile="test.csv",method="curl")
training <- read.csv(training.csv)
testsing <- read.csv(testing.csv)
training <- read.csv(train.csv)
testsing <- read.csv(test.csv)
training <- read.csv("train.csv")
testsing <- read.csv("test.csv")
str(training)
head(training$class)
?vapply
sapply(training, summary)
str(testing)
testsing <- read.csv("test.csv")
testing <- read.csv("test.csv")
str(testing)
library(caret)
dataset <- read.csv("train.csv")
summary(dataset$classe)
inTrain <- createDataPartition(dataset$classe,p=0.7,list=FALSE)
training <- dataset[inTrain,]
testing <- dataset[-inTrain,]
modFit <- train(classe~., method="rf",data=training,prox=TRUE)
test_pred <- read.csv("test.csv")
str(test_pred)
summary(test_pred$kurtosis_roll_dumbbell)
nsv <- nearZeroVar(training, saveMetrics = TRUE)
nsv
dim(nsv[nsv$nzv="FALSE",1])
dim(nsv[nsv$nzv=="FALSE",1])
str(nsv[nsv$nzv=="FALSE",1])
str(training)
str(test_pred)
nsv_pred <- nearZeroVar(test_pred, saveMetrics = TRUE)
nsv_pred
str(nsv[nsv_pred$nzv=="FALSE",1])
dataset <- read.csv("train.csv")
inTrain <- createDataPartition(dataset$classe,p=0.7,list=FALSE)
training <- dataset[inTrain,]
testing <- dataset[-inTrain,]
dim(training)
stats_id <- c("kurtosis","skewness","max","min","amplitude","avg","stddev","var")
col_remove <-c()
for(i in keys){
k <- grep(i, names(training), value = F)
col_remove <- c(col_remove, as.integer(k))
}
#The first 7 columns are housekeeping items and also need to be removed
col_remove <- c(1:7,col_remove)
training <- training[,-col_remove]
testing <- tesing[,-col_remove]
dataset <- read.csv("train.csv")
inTrain <- createDataPartition(dataset$classe,p=0.7,list=FALSE)
training <- dataset[inTrain,]
testing <- dataset[-inTrain,]
#Exploring Training Data
str(training)
dim(training)
#There are 160 variables.  After careful examination of the variable, some of the variables are statistical properties such
#kurtosis, min, max, etc.  I will remove those variables since they are not predictive variables
#Data Preprocessing
#identify columns with statistical properties
stats_id <- c("kurtosis","skewness","max","min","amplitude","avg","stddev","var")
col_remove <-c()
for(i in keys){
k <- grep(i, names(training), value = F)
col_remove <- c(col_remove, as.integer(k))
}
#The first 7 columns are housekeeping items and also need to be removed
col_remove <- c(1:7,col_remove)
training <- training[,-col_remove]
testing <- tesing[,-col_remove]
stats_id <- c("kurtosis","skewness","max","min","amplitude","avg","stddev","var")
col_remove <-c()
for(i in stats_id){
k <- grep(i, names(training), value = F)
col_remove <- c(col_remove, as.integer(k))
}
#The first 7 columns are housekeeping items and also need to be removed
col_remove <- c(1:7,col_remove)
training <- training[,-col_remove]
testing <- tesing[,-col_remove]
testing <- testing[,-col_remove]
dim(training)
dim(testing)
testing <- testing[,-col_remove]
dim(testing)
training <- dataset[inTrain,]
testing <- dataset[-inTrain,]
training <- training[,-col_remove]
testing <- testing[,-col_remove]
dim(training)
dim(testing)
preProc <- preProcess(training[,-dim(training)[2]], method='pca',thresh=0.9)
preProc
library(caret)
str(training)
training <- dataset[inTrain,]
testing <- dataset[-inTrain,]
dim(training)
stats_id <- c("kurtosis","skewness","max","min","amplitude","avg","stddev","var")
col_remove <-c()
for(i in stats_id){
k <- grep(i, names(training), value = F)
col_remove <- c(col_remove, as.integer(k))
}
col_remove <- c(c(1:7),col_remove)
training <- training[,-col_remove]
testing <- testing[,-col_remove]
dim(training)
dim(testing)
preProc <- preProcess(training[,-dim(training)[2]], method='pca',thresh=0.9)
preProc
preProc <- preProcess(training[,-dim(training)[2]], method='pca',thresh=0.95)
preProc
preProc <- preProcess(training[,-dim(training)[2]], method='pca',thresh=0.90)
preProc
modFit <- train(classe~., method="rf",preProcess="pca",data=training)
confusionMatrix(training$classe,predict(modFit,tesing))
confusionMatrix(training$classe,predict(modFit,testing))
confusionMatrix(training$classe,predict(modFit))
confusionMatrix(testing$classe,predict(modFit,testing))
test_pred <- read.csv("test.csv")
test_pred <- test.pred[,-col_remove]
stats_id <- c("kurtosis","skewness","max","min","amplitude","avg","stddev","var")
col_remove <-c()
for(i in stats_id){
k <- grep(i, names(training), value = F)
col_remove <- c(col_remove, as.integer(k))
}
#The first 7 columns are housekeeping items and also need to be removed
col_remove <- c(c(1:7),col_remove)
test_pred <- test.pred[,-col_remove]
test_pred <- test_pred[,-col_remove]
dim(test_pred)
test_pred <- read.csv("test.csv")
test_pred <- test_pred[,-col_remove]
dim(test_pred)
col_remove
training <- dataset[inTrain,]
testing <- dataset[-inTrain,]
stats_id <- c("kurtosis","skewness","max","min","amplitude","avg","stddev","var")
col_remove <-c()
for(i in stats_id){
k <- grep(i, names(training), value = F)
col_remove <- c(col_remove, as.integer(k))
}
#The first 7 columns are housekeeping items and also need to be removed
col_remove <- c(c(1:7),col_remove)
test_pred <- test_pred[,-col_remove]
dim(test_pred)
training <- dataset[inTrain,]
testing <- dataset[-inTrain,]
stats_id <- c("kurtosis","skewness","max","min","amplitude","avg","stddev","var")
col_remove <-c()
for(i in stats_id){
k <- grep(i, names(training), value = F)
col_remove <- c(col_remove, as.integer(k))
}
#The first 7 columns are housekeeping items and also need to be removed
col_remove <- c(c(1:7),col_remove)
test_pred <- read.csv("test.csv")
test_pred <- test_pred[,-col_remove]
dim(test_pred)
predict(modFit,test_pred)
B A A A A E D B A A B C B A E E A B B B
B A B A A E D B A A A C B A E E A B B B
B A A A A E D B A A B C B A E E A B B B
write_class_predictions_to_file = function(x) {
for (k in 1:length(x)) {
file_name = paste0("problem_id_",k,".txt")
write.table(x[k],file=file_name, quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
prediction <- predict(modFit,test_pred)
prediction
prediction(2)<-"A"
prediction[2]<-"A"
prediction
prediction <- predict(modFit,test_pred)
prediction
write_class_predictions_to_file(prediction)
